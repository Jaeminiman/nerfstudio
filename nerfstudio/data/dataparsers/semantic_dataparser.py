# [CUSTOM] Semantic Dataparser for NeRFStudio
# Extends the Nerfstudio dataparser to load semantic mask paths and metadata
# from transforms.json generated by prepare_semantic_data.py

from __future__ import annotations

from dataclasses import dataclass, field
from pathlib import Path
from typing import List, Optional, Type

import torch

from nerfstudio.data.dataparsers.nerfstudio_dataparser import (
    Nerfstudio,
    NerfstudioDataParserConfig,
)
from nerfstudio.data.dataparsers.base_dataparser import DataparserOutputs, Semantics
from nerfstudio.utils.io import load_from_json
from nerfstudio.utils.rich_utils import CONSOLE



@dataclass
class SemanticDataParserConfig(NerfstudioDataParserConfig):
    """Semantic Nerfstudio dataset config - extends base config with semantic support"""

    _target: Type = field(default_factory=lambda: SemanticDataParser)
    """target class to instantiate"""
    semantics_mask_classes: List[str] = field(default_factory=list)
    """Classes to mask out from training (for valid_mask, NOT semantic_mask)"""


@dataclass
class SemanticDataParser(Nerfstudio):
    """Semantic DatasetParser - extends Nerfstudio parser with semantic data loading
    
    This parser reads the extended transforms.json format that includes:
    - semantics_path per frame (path to semantic mask PNG)
    - semantics_classes (list of class names)
    - semantics_colors (list of RGB colors per class)
    - semantics_weights (list of class weights for loss balancing)
    """

    config: SemanticDataParserConfig

    def _generate_dataparser_outputs(self, split="train") -> DataparserOutputs:
        # Get base outputs from parent class
        dataparser_outputs = super()._generate_dataparser_outputs(split)
        
        # Load transforms.json to get semantic metadata
        if self.config.data.suffix == ".json":
            meta = load_from_json(self.config.data)
            data_dir = self.config.data.parent
        else:
            meta = load_from_json(self.config.data / "transforms.json")
            data_dir = self.config.data
            
        # Check if semantic data is available
        has_semantics = "semantics_classes" in meta
        
        if not has_semantics:
            CONSOLE.print("[yellow]Warning: No semantic data found in transforms.json. "
                          "Semantic features will not be available.[/yellow]")
            return dataparser_outputs
        
        # Parse semantic classes and colors
        semantics_classes: List[str] = meta.get("semantics_classes", [])
        semantics_colors_list = meta.get("semantics_colors", [])
        semantics_weights_list = meta.get("semantics_weights", [])
        
        if not semantics_classes:
            CONSOLE.print("[yellow]Warning: Empty semantics_classes in transforms.json.[/yellow]")
            return dataparser_outputs
        
        # Convert colors to tensor [N_classes, 3]
        semantics_colors = torch.tensor(semantics_colors_list, dtype=torch.float32) / 255.0
        
        # Convert weights to tensor [N_classes]
        if semantics_weights_list:
            semantics_weights = torch.tensor(semantics_weights_list, dtype=torch.float32)
        else:
            # Default to uniform weights
            semantics_weights = torch.ones(len(semantics_classes), dtype=torch.float32)
        
        # Collect semantic filenames from frames
        # We need to match the order with the filtered image_filenames in dataparser_outputs
        # The parent class already filters by split, so we need to do the same filtering
        
        # Re-sort frames as parent does
        import numpy as np
        fnames = []
        for frame in meta["frames"]:
            filepath = Path(frame["file_path"])
            fname = self._get_fname(filepath, data_dir)
            fnames.append(fname)
        inds = np.argsort(fnames)
        frames = [meta["frames"][ind] for ind in inds]
        
        # Get the same indices as parent class uses for this split
        # We need to rebuild this logic or use the image_filenames to filter
        output_image_filenames = set(dataparser_outputs.image_filenames)
        
        semantic_filenames: List[Path] = []
        for frame in frames:
            filepath = Path(frame["file_path"])
            fname = self._get_fname(filepath, data_dir)
            
            # Only include if this frame is in the output
            if fname in output_image_filenames:
                if "semantics_path" in frame:
                    sem_path = Path(frame["semantics_path"])
                    # Handle relative paths
                    if not sem_path.is_absolute():
                        sem_path = data_dir / sem_path
                    semantic_filenames.append(sem_path)
                else:
                    CONSOLE.print(f"[yellow]Warning: Frame {fname} missing semantics_path[/yellow]")
                    # Use a placeholder or skip - for now add None equivalent path
                    semantic_filenames.append(None)
        
        # Filter out None entries and ensure length matches
        valid_semantic_filenames = [f for f in semantic_filenames if f is not None]
        
        if len(valid_semantic_filenames) != len(dataparser_outputs.image_filenames):
            CONSOLE.print(f"[yellow]Warning: Semantic filenames count ({len(valid_semantic_filenames)}) "
                          f"doesn't match image count ({len(dataparser_outputs.image_filenames)}). "
                          f"Some frames may be missing semantic data.[/yellow]")
            # Pad with first valid path or handle differently
            if valid_semantic_filenames:
                while len(valid_semantic_filenames) < len(dataparser_outputs.image_filenames):
                    valid_semantic_filenames.append(valid_semantic_filenames[0])
            semantic_filenames = valid_semantic_filenames
        else:
            semantic_filenames = valid_semantic_filenames
        
        # Create Semantics object
        semantics = Semantics(
            filenames=semantic_filenames,
            classes=semantics_classes,
            colors=semantics_colors,
            mask_classes=self.config.semantics_mask_classes,
        )
        
        # Update metadata with semantics
        new_metadata = dict(dataparser_outputs.metadata)
        new_metadata["semantics"] = semantics
        new_metadata["semantics_weights"] = semantics_weights
        new_metadata["semantics_colormap"] = semantics_colors
        
        # Create new DataparserOutputs with updated metadata
        dataparser_outputs = DataparserOutputs(
            image_filenames=dataparser_outputs.image_filenames,
            cameras=dataparser_outputs.cameras,
            alpha_color=dataparser_outputs.alpha_color,
            scene_box=dataparser_outputs.scene_box,
            mask_filenames=dataparser_outputs.mask_filenames,
            metadata=new_metadata,
            dataparser_transform=dataparser_outputs.dataparser_transform,
            dataparser_scale=dataparser_outputs.dataparser_scale,
        )
        
        CONSOLE.print(f"[green]Loaded semantic data: {len(semantics_classes)} classes, "
                      f"{len(semantic_filenames)} masks[/green]")
        
        return dataparser_outputs
